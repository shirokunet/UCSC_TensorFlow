{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Pre- trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "We are reading MNIST data from https://github.com/zalandoresearch/fashion-mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "fashion_mnist = input_data.read_data_sets('data/fashion',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(fashion_mnist.train.num_examples) # Number of training data\n",
    "print(fashion_mnist.test.num_examples) # Number of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1209bceb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bfac9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_1 = fashion_mnist.train.images[47].reshape(28,28)\n",
    "plt.imshow(sample_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture hyper-parameter\n",
    "learning_rate = 0.01\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 20\n",
    "\n",
    "n_input = 784 # 28x28 image\n",
    "n_classes = 10 # 1 for each digit [0-9]\n",
    "dropout = 0.75 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model using conv2d, Relu and Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # reshape input to 28x28 size\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution layer 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max pooling\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution layer 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max pooling\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#writer = tf.summary.FileWriter(\"./logs/2.2\")\n",
    "\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "#g=tf.get_default_graph()\n",
    "\n",
    "#v1 = tf.get_variable(\"v1\", [3], initializer = tf.zeros_initializer)\n",
    "\n",
    "#\n",
    "#with tf.name_scope('restored_weights') as scope:\n",
    "#biases = {\n",
    " #   'bc1': tf.Variable(tf.random_normal([32]),name='bc1'),\n",
    "  #  'bc2': tf.Variable(tf.random_normal([64]),name='bc2'),\n",
    "   # 'bd1': tf.Variable(tf.random_normal([1024]),name='bd1'),\n",
    "    #'out': tf.Variable(tf.random_normal([n_classes]),name='b4')\n",
    "# }\n",
    "\n",
    "#with tf.Session(graph=g) as sess1:\n",
    "            # Load model\n",
    "\n",
    "        #saver = tf.train.import_meta_graph('check/model.ckpt.meta')    #\n",
    "       # saver=tf.train.Saver(biases)\n",
    "        #sess1.run(tf.global_variables_initializer())\n",
    "\n",
    "       # saver.restore(sess1,\"check/model.ckpt\")\n",
    "\n",
    "      \n",
    "       # writer.add_graph(sess1.graph)\n",
    "\n",
    "        # print(biases) \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784) (?, 10)\n",
      "INFO:tensorflow:Restoring parameters from check/model.ckpt\n",
      "biases:\n",
      "{'out': array([ 1.8140063 , -1.3549004 , -0.6972118 , -0.03704418, -0.575428  ,\n",
      "        1.1613044 ,  1.2955763 , -0.4012211 , -0.35322228, -0.6027212 ],\n",
      "      dtype=float32), 'bc2': array([ 1.6188246e-01,  1.8329057e+00, -1.1416315e-01,  1.7724207e-01,\n",
      "       -8.3075011e-01, -2.6711437e-01,  3.8837942e-01, -3.9513558e-01,\n",
      "       -4.2339653e-01,  1.1462628e-01, -1.5952190e+00, -1.4591267e+00,\n",
      "       -1.8177141e-01, -3.2456908e-01,  7.4565566e-01, -4.3686548e-01,\n",
      "       -1.7489035e+00,  3.4718782e-01,  5.4944181e-01,  4.6394423e-01,\n",
      "       -6.9039494e-01,  4.9477255e-01, -4.4093597e-01, -1.7258165e+00,\n",
      "        6.5273494e-01,  1.9512705e-03, -9.0393674e-01, -9.3420136e-01,\n",
      "        9.0186530e-01,  1.7082271e-01,  2.4077423e-01, -1.1224726e+00,\n",
      "        8.2932150e-01, -4.0650907e-01, -1.5819722e+00, -5.6590515e-01,\n",
      "       -2.9995006e-01, -9.6639067e-01,  3.2130635e-01, -2.1968207e+00,\n",
      "        7.8072868e-02, -2.3994806e+00, -6.3948393e-02, -9.4757307e-01,\n",
      "        1.3052627e+00, -2.2414608e+00, -5.3807431e-01, -4.2880222e-01,\n",
      "        8.3397686e-01,  1.0051028e+00, -6.5659332e-01, -1.9358134e-01,\n",
      "        1.1750142e-01,  7.0618302e-01, -1.4441237e+00,  1.6948797e+00,\n",
      "       -7.8954512e-01, -8.5906017e-01,  1.1831188e+00,  3.5889620e-01,\n",
      "        1.1972443e+00,  5.5969292e-01, -1.9946194e+00,  1.9259745e-01],\n",
      "      dtype=float32), 'bd1': array([-0.5985217, -0.5619659, -0.5516432, ..., -0.4020257, -1.140926 ,\n",
      "        0.5758896], dtype=float32), 'bc1': array([-1.1027954 , -1.567285  ,  1.3777894 ,  0.05062915,  1.0295513 ,\n",
      "        0.93644416, -1.4085357 , -0.21604203,  0.5769824 , -2.8046684 ,\n",
      "        1.2673656 ,  0.03606503,  0.9648196 , -0.7284922 , -0.00806318,\n",
      "       -0.7814117 ,  0.06287194, -0.31141677,  0.8358811 , -0.4127526 ,\n",
      "       -0.42291468, -3.3701246 , -1.8836257 , -1.2196177 , -0.7296153 ,\n",
      "       -1.8206197 , -1.097017  ,  2.14674   ,  0.40917945, -0.9639401 ,\n",
      "        0.6521735 ,  0.92794955], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter(\"./logs/2\")\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32]),name='wc1'),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64]),name='wc2'),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024]),name=\"wd1\"),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]),name=\"w4\")\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32]),name='bc1'),\n",
    "    'bc2': tf.Variable(tf.random_normal([64]),name='bc2'),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024]),name='bd1'),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]),name='b4')\n",
    "}\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess1:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess1,\"check/model.ckpt\")\n",
    "    print('biases:')\n",
    "    print(sess1.run(biases))\n",
    "    writer.add_graph(sess1.graph)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost, optimizer and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_model = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_model, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the session \n",
    "This will run the graph and use all the tensors that were previously defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2560, Loss= 2473.970, Training Accuracy= 0.656\n",
      "Iter 5120, Loss= 708.868, Training Accuracy= 0.711\n",
      "Iter 7680, Loss= 335.930, Training Accuracy= 0.805\n",
      "Iter 10240, Loss= 292.193, Training Accuracy= 0.812\n",
      "Iter 12800, Loss= 429.062, Training Accuracy= 0.773\n",
      "Iter 15360, Loss= 386.478, Training Accuracy= 0.781\n",
      "Iter 17920, Loss= 190.115, Training Accuracy= 0.812\n",
      "Iter 20480, Loss= 156.169, Training Accuracy= 0.836\n",
      "Iter 23040, Loss= 228.950, Training Accuracy= 0.766\n",
      "Iter 25600, Loss= 132.442, Training Accuracy= 0.812\n",
      "Iter 28160, Loss= 98.211, Training Accuracy= 0.844\n",
      "Iter 30720, Loss= 130.019, Training Accuracy= 0.766\n",
      "Iter 33280, Loss= 148.222, Training Accuracy= 0.750\n",
      "Iter 35840, Loss= 157.330, Training Accuracy= 0.789\n",
      "Iter 38400, Loss= 112.429, Training Accuracy= 0.820\n",
      "Iter 40960, Loss= 107.937, Training Accuracy= 0.789\n",
      "Iter 43520, Loss= 94.833, Training Accuracy= 0.789\n",
      "Iter 46080, Loss= 126.832, Training Accuracy= 0.719\n",
      "Iter 48640, Loss= 81.217, Training Accuracy= 0.766\n",
      "Iter 51200, Loss= 73.540, Training Accuracy= 0.766\n",
      "Iter 53760, Loss= 46.600, Training Accuracy= 0.812\n",
      "Iter 56320, Loss= 68.749, Training Accuracy= 0.758\n",
      "Iter 58880, Loss= 66.033, Training Accuracy= 0.703\n",
      "Iter 61440, Loss= 49.660, Training Accuracy= 0.688\n",
      "Iter 64000, Loss= 26.885, Training Accuracy= 0.805\n",
      "Iter 66560, Loss= 25.846, Training Accuracy= 0.781\n",
      "Iter 69120, Loss= 43.856, Training Accuracy= 0.711\n",
      "Iter 71680, Loss= 29.072, Training Accuracy= 0.750\n",
      "Iter 74240, Loss= 33.540, Training Accuracy= 0.719\n",
      "Iter 76800, Loss= 21.807, Training Accuracy= 0.789\n",
      "Iter 79360, Loss= 36.057, Training Accuracy= 0.742\n",
      "Iter 81920, Loss= 19.381, Training Accuracy= 0.805\n",
      "Iter 84480, Loss= 20.222, Training Accuracy= 0.695\n",
      "Iter 87040, Loss= 14.532, Training Accuracy= 0.742\n",
      "Iter 89600, Loss= 7.197, Training Accuracy= 0.781\n",
      "Iter 92160, Loss= 14.601, Training Accuracy= 0.711\n",
      "Iter 94720, Loss= 12.812, Training Accuracy= 0.562\n",
      "Iter 97280, Loss= 8.426, Training Accuracy= 0.633\n",
      "Iter 99840, Loss= 9.925, Training Accuracy= 0.633\n",
      "Testing Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = fashion_mnist.train.next_batch(batch_size)   \n",
    "        #print(batch_x.shape, batch_y.shape)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Loss= \" + \\\n",
    "                  \"{:.3f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "        step += 1\n",
    "    \n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: fashion_mnist.test.images[:256],\n",
    "                                      y: fashion_mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The testing acccuracy has improved than the normal fashion_mnist after applying weights from the mnist data which yielded just 19.5% accuracy.The accuracy improved from 19.5% to 62.5 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for the biases are same from checked point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  b4\n",
      "[ 1.8140063  -1.3549004  -0.6972118  -0.03704418 -0.575428    1.1613044\n",
      "  1.2955763  -0.4012211  -0.35322228 -0.6027212 ]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "chkp.print_tensors_in_checkpoint_file(\"check/model.ckpt\",tensor_name='b4', all_tensors=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nteract": {
   "version": "0.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
